{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "For Project 2, I decided to try out CNN on image classification. Having to watch an anime called the \"Quinsential Quintuplet\" which is a show of quintuplet having to be tutored by a guy as they were having bad grades. Apprently, they can be very hard to be tell apart if they all dress the same and only the granparent have a way to tell them apart. Hence, I will only be identifying two of the sisters out of the 5 as they are more popular towards the community and there are numerous of fan arts which means more data for me. ☆*:.｡.o(≧▽≦)o.｡.:*☆\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection ٩(◕‿◕｡)۶\t\n",
    "\n",
    "Since I have tried playing with these datasets quite a while back, I realize that training the picture as whole is 100% not the ideal kind of situation as firstly, it will take up alot of time to train each image and secondly, if the image is not consistent, the model would not even know what the user wants to detect. Hence, for that purpose, i actually have crop out features that I want the model to \"see\" and recognize. \n",
    "\n",
    "For example, Miku, 1 of the 5 sister, is always constantly wearing a headphone. Hence, I would crop the photo that is inclusive of the headphone. This way, I think that when the model is training, it will know what it needs to detect as the \"focus range\" is more specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite having the community to support the show and drawing those fan arts, the good ones that I found are very limited. Hence, to artifically create more dataset, we will have to augment most of the photos we have to increase the size of the dataset. Augmenting dataset means that the traning dataset are created by modifying versions of images in the dataset.\n",
    "\n",
    "Despite the fact that there are many ways to augment an image such as playing with the image brightness, position, aspect ratio, shifts, flips, zooms, and much more. It must be clear that the choice of the specific data augmentation techniques used for a training dataset must be chosen carefully and within the context of the training dataset and knowledge of the problem domain so that it will acutally helps you and not make things worse.\n",
    "\n",
    "Image data augmentation is typically only applied to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- matplotlib  to use the \"Agg\"  backend enabling us to save plots to disk — that’s your first nuance!\n",
    "- openCV will be reading our image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLEASE CHANGE TO NO ARGUMENTS NEEDED\n",
    "\n",
    "$ python train_simple_nn.py --dataset animals --model output/simple_nn.model --label-bin output/simple_nn_lb.pickle --plot output/simple_nn_plot.png# PLEASE CHANGE TO NO ARGUMENTS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -d DATASET -m MODEL -l LABEL_BIN -p PLOT\n",
      "ipykernel_launcher.py: error: the following arguments are required: -d/--dataset, -m/--model, -l/--label-bin, -p/--plot\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oslost/.virtualenvs/conda_fake/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "    help=\"path to input dataset of images\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "    help=\"path to output trained model\")\n",
    "ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "    help=\"path to output label binarizer\")\n",
    "ap.add_argument(\"-p\", \"--plot\", required=True,\n",
    "    help=\"path to output accuracy/loss plot\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- --dataset : The path to our dataset of images on disk.\n",
    "- --model : Our model will be serialized and output to disk. This argument contains the path to the output model   file.\n",
    "- --label-bin : Dataset labels are serialized to disk for easy recall in other scripts. This is the path to the output label binarizer file.\n",
    "- --plot : The path to the output training plot image file. We’ll review this plot to check for over/underfitting of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keras Tutorial: How to get started with Keras, Deep Learning, and PythonPython\n",
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(\"dataset\")))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, resize the image to be 32x32 pixels (ignoring\n",
    "    # aspect ratio), flatten the image into 32x32x3=3072 pixel image\n",
    "    # into a list, and store the image in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (32, 32)).flatten()\n",
    "    # Add image to the data array\n",
    "    data.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our class labels are currently represented as strings; however, Keras will assume that both:\n",
    "\n",
    "Labels are encoded as integers\n",
    "And furthermore, one-hot encoding is performed on these labels making each label represented as a vector rather than an integer\n",
    "To accomplish this encoding, we can use the LabelBinarizer  class from scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors (for 2-class, binary\n",
    "# classification you should use Keras' to_categorical function\n",
    "# instead as the scikit-learn's LabelBinarizer will not return a\n",
    "# vector)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the 3072-1024-512-3 architecture using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input layer and first hidden layer are defined on Line 76. will have an input_shape  of 3072  as there are 32x32x3=3072  pixels in a flattened input image. The first hidden layer will have 1024  nodes.\n",
    "\n",
    "The second hidden layer will have 512  nodes (Line 77).\n",
    "\n",
    "Finally, the number of nodes in the final output layer (Line 78) will be the number of possible class labels — in this case, the output layer will have three nodes, one for each of our class labels (“cats”, “dogs”, and “panda”, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our initial learning rate and # of epochs to train for\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    " \n",
    "# compile the model using SGD as our optimizer and categorical\n",
    "# cross-entropy loss (you'll want to use binary_crossentropy\n",
    "# for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=EPOCHS, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n",
    " \n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(args[\"model\"])\n",
    "f = open(args[\"label_bin\"], \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python predict.py --image images/cat.jpg --model output/simple_nn.model \\\n",
    "    --label-bin output/simple_nn_lb.pickle --width 32 --height 32 --flatten 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import load_model\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "\n",
    " \n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "    help=\"path to input image we are going to classify\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "    help=\"path to trained Keras model\")\n",
    "ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "    help=\"path to label binarizer\")\n",
    "ap.add_argument(\"-w\", \"--width\", type=int, default=28,\n",
    "    help=\"target spatial dimension width\")\n",
    "ap.add_argument(\"-e\", \"--height\", type=int, default=28,\n",
    "    help=\"target spatial dimension height\")\n",
    "ap.add_argument(\"-f\", \"--flatten\", type=int, default=-1,\n",
    "    help=\"whether or not we should flatten the image\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll need to explicitly import load_model  from keras.models  whenever you write a script to load a Keras model from disk. OpenCV will be used for annotation and display. The pickle  module will be used to load our label binarizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- --image : The path to our input image.\n",
    "- --model : Our trained and serialized Keras model path.\n",
    "- --label-bin : Path to the serialized label binarizer.\n",
    "- --width : The width of the input shape for our CNN. Remember — you can’t just specify anything here. You need to specify the width that the model is designed for.\n",
    "- --height : The height of the image input to the CNN. The height specified must also match the network’s input shape.\n",
    "- --flatten : Whether or not we should flatten the image. By default, we won’t flatten the image. If you need to flatten the image, you should pass a 1  for this argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image and resize it to the target spatial dimensions\n",
    "image = cv2.imread(args[\"image\"])\n",
    "output = image.copy()\n",
    "image = cv2.resize(image, (args[\"width\"], args[\"height\"]))\n",
    " \n",
    "# scale the pixel values to [0, 1]\n",
    "image = image.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if we should flatten the image and add a batch\n",
    "# dimension\n",
    "if args[\"flatten\"] > 0:\n",
    "    image = image.flatten()\n",
    "    image = image.reshape((1, image.shape[0]))\n",
    "\n",
    "# otherwise, we must be working with a CNN -- don't flatten the\n",
    "# image, simply add the batch dimension\n",
    "else:\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1],\n",
    "        image.shape[2]))\n",
    "\n",
    "# check to see if we should flatten the image and add a batch\n",
    "# dimension\n",
    "if args[\"flatten\"] > 0:\n",
    "    image = image.flatten()\n",
    "    image = image.reshape((1, image.shape[0]))\n",
    " \n",
    "# otherwise, we must be working with a CNN -- don't flatten the\n",
    "# image, simply add the batch dimension\n",
    "else:\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1],\n",
    "    image.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and label binarizer\n",
    "print(\"[INFO] loading network and label binarizer...\")\n",
    "model = load_model(args[\"model\"])\n",
    "lb = pickle.loads(open(args[\"label_bin\"], \"rb\").read())\n",
    " \n",
    "# make a prediction on the image\n",
    "preds = model.predict(image)\n",
    " \n",
    "# find the class label index with the largest corresponding\n",
    "# probability\n",
    "i = preds.argmax(axis=1)[0]\n",
    "label = lb.classes_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the class label + probability on the output image\n",
    "text = \"{}: {:.2f}%\".format(label, preds[0][i] * 100)\n",
    "cv2.putText(output, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    " \n",
    "# show the output image\n",
    "cv2.imshow(\"Image\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><b>References</b></h1><center>\n",
    "    \n",
    "    \n",
    "1. Data Augmentation : https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "2. Keras with DL : https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
